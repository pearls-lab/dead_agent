pygame 2.1.3 (SDL 2.0.22, Python 3.11.1)
Hello from the pygame community. https://www.pygame.org/contribute.html
Folder subpath:  64_64_64/
Making directory:  /root/home/gridworld/graphs/64_64_64/dqn/
/root/home/gridworld/graphs/64_64_64/dqn/
Using cuda device
Wrapping the env in a DummyVecEnv.
subspaces: {None: Box(-99.0, 100.0, (100,), float64)}
Keys [None]
Shapes: {None: (100,)}
Testing algo: dqn
Model size: DQNPolicy(
  (q_net): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): Linear(in_features=100, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): ReLU()
      (6): Linear(in_features=64, out_features=4, bias=True)
    )
  )
  (q_net_target): QNetwork(
    (features_extractor): FlattenExtractor(
      (flatten): Flatten(start_dim=1, end_dim=-1)
    )
    (q_net): Sequential(
      (0): Linear(in_features=100, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): ReLU()
      (6): Linear(in_features=64, out_features=4, bias=True)
    )
  )
)
subspaces: {None: Box(-99.0, 100.0, (100,), float64)}
Keys [None]
Shapes: {None: (100,)}
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 3.75     |
|    ep_rew_mean      | -0.0375  |
|    exploration_rate | 0.88     |
| time/               |          |
|    episodes         | 4        |
|    fps              | 2202     |
|    time_elapsed     | 0        |
|    total_timesteps  | 15       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 5.75     |
|    ep_rew_mean      | -0.0575  |
|    exploration_rate | 0.632    |
| time/               |          |
|    episodes         | 8        |
|    fps              | 4078     |
|    time_elapsed     | 0        |
|    total_timesteps  | 46       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 5.25     |
|    ep_rew_mean      | -0.0525  |
|    exploration_rate | 0.496    |
| time/               |          |
|    episodes         | 12       |
|    fps              | 4569     |
|    time_elapsed     | 0        |
|    total_timesteps  | 63       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 10.2     |
|    ep_rew_mean      | -0.102   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 16       |
|    fps              | 365      |
|    time_elapsed     | 0        |
|    total_timesteps  | 163      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00259  |
|    n_updates        | 15       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 23       |
|    ep_rew_mean      | -0.23    |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 20       |
|    fps              | 482      |
|    time_elapsed     | 0        |
|    total_timesteps  | 460      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000524 |
|    n_updates        | 89       |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 20.2     |
|    ep_rew_mean      | -0.203   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 24       |
|    fps              | 490      |
|    time_elapsed     | 0        |
|    total_timesteps  | 486      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00106  |
|    n_updates        | 96       |
----------------------------------
Eval num_timesteps=500, episode_reward=-0.06 +/- 0.03
Episode length: 6.00 +/- 2.76
----------------------------------
| eval/               |          |
|    mean_ep_length   | 6        |
|    mean_reward      | -0.06    |
| rollout/            |          |
|    exploration_rate | 0.2      |
| time/               |          |
|    total_timesteps  | 500      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000295 |
|    n_updates        | 99       |
----------------------------------
New best mean reward!
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 18.4     |
|    ep_rew_mean      | -0.184   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 28       |
|    fps              | 479      |
|    time_elapsed     | 1        |
|    total_timesteps  | 515      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00044  |
|    n_updates        | 103      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 16.8     |
|    ep_rew_mean      | -0.168   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 32       |
|    fps              | 485      |
|    time_elapsed     | 1        |
|    total_timesteps  | 536      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000236 |
|    n_updates        | 108      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 15.6     |
|    ep_rew_mean      | -0.156   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 36       |
|    fps              | 495      |
|    time_elapsed     | 1        |
|    total_timesteps  | 562      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000479 |
|    n_updates        | 115      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 14.7     |
|    ep_rew_mean      | -0.147   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 40       |
|    fps              | 502      |
|    time_elapsed     | 1        |
|    total_timesteps  | 586      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000601 |
|    n_updates        | 121      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 13.8     |
|    ep_rew_mean      | -0.138   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 44       |
|    fps              | 506      |
|    time_elapsed     | 1        |
|    total_timesteps  | 605      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000203 |
|    n_updates        | 126      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 13       |
|    ep_rew_mean      | -0.13    |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 48       |
|    fps              | 514      |
|    time_elapsed     | 1        |
|    total_timesteps  | 624      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 130      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 12.5     |
|    ep_rew_mean      | -0.125   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 52       |
|    fps              | 520      |
|    time_elapsed     | 1        |
|    total_timesteps  | 649      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000353 |
|    n_updates        | 137      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 12.1     |
|    ep_rew_mean      | -0.121   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 56       |
|    fps              | 528      |
|    time_elapsed     | 1        |
|    total_timesteps  | 679      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000274 |
|    n_updates        | 144      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 11.7     |
|    ep_rew_mean      | -0.117   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 60       |
|    fps              | 531      |
|    time_elapsed     | 1        |
|    total_timesteps  | 702      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000218 |
|    n_updates        | 150      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 11.2     |
|    ep_rew_mean      | -0.112   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 64       |
|    fps              | 526      |
|    time_elapsed     | 1        |
|    total_timesteps  | 714      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000222 |
|    n_updates        | 153      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 10.9     |
|    ep_rew_mean      | -0.109   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 68       |
|    fps              | 530      |
|    time_elapsed     | 1        |
|    total_timesteps  | 738      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.00019  |
|    n_updates        | 159      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 10.6     |
|    ep_rew_mean      | -0.106   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 72       |
|    fps              | 536      |
|    time_elapsed     | 1        |
|    total_timesteps  | 761      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000153 |
|    n_updates        | 165      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 10.2     |
|    ep_rew_mean      | -0.102   |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 76       |
|    fps              | 539      |
|    time_elapsed     | 1        |
|    total_timesteps  | 774      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.49e-05 |
|    n_updates        | 168      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 9.88     |
|    ep_rew_mean      | -0.0988  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 80       |
|    fps              | 544      |
|    time_elapsed     | 1        |
|    total_timesteps  | 790      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.85e-05 |
|    n_updates        | 172      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 9.63     |
|    ep_rew_mean      | -0.0963  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 84       |
|    fps              | 549      |
|    time_elapsed     | 1        |
|    total_timesteps  | 809      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 6.19e-05 |
|    n_updates        | 177      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 9.32     |
|    ep_rew_mean      | -0.0932  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 88       |
|    fps              | 552      |
|    time_elapsed     | 1        |
|    total_timesteps  | 820      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000103 |
|    n_updates        | 179      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 9.09     |
|    ep_rew_mean      | -0.0909  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 92       |
|    fps              | 549      |
|    time_elapsed     | 1        |
|    total_timesteps  | 836      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 8.51e-05 |
|    n_updates        | 183      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 8.84     |
|    ep_rew_mean      | -0.0884  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 96       |
|    fps              | 545      |
|    time_elapsed     | 1        |
|    total_timesteps  | 849      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.000161 |
|    n_updates        | 187      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 8.63     |
|    ep_rew_mean      | -0.0863  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 100      |
|    fps              | 548      |
|    time_elapsed     | 1        |
|    total_timesteps  | 863      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 0.0002   |
|    n_updates        | 190      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 8.66     |
|    ep_rew_mean      | -0.0866  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 104      |
|    fps              | 551      |
|    time_elapsed     | 1        |
|    total_timesteps  | 881      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.8e-05  |
|    n_updates        | 195      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 8.52     |
|    ep_rew_mean      | -0.0852  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 108      |
|    fps              | 554      |
|    time_elapsed     | 1        |
|    total_timesteps  | 898      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 4.73e-05 |
|    n_updates        | 199      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 8.54     |
|    ep_rew_mean      | -0.0854  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 112      |
|    fps              | 554      |
|    time_elapsed     | 1        |
|    total_timesteps  | 917      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 7.06e-05 |
|    n_updates        | 204      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 7.68     |
|    ep_rew_mean      | -0.0768  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 116      |
|    fps              | 555      |
|    time_elapsed     | 1        |
|    total_timesteps  | 931      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 2.91e-05 |
|    n_updates        | 207      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 4.86     |
|    ep_rew_mean      | -0.0486  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 120      |
|    fps              | 555      |
|    time_elapsed     | 1        |
|    total_timesteps  | 946      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.78e-05 |
|    n_updates        | 211      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 4.77     |
|    ep_rew_mean      | -0.0477  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 124      |
|    fps              | 553      |
|    time_elapsed     | 1        |
|    total_timesteps  | 963      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.63e-05 |
|    n_updates        | 215      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 4.64     |
|    ep_rew_mean      | -0.0464  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 128      |
|    fps              | 550      |
|    time_elapsed     | 1        |
|    total_timesteps  | 979      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 5.25e-05 |
|    n_updates        | 219      |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 4.57     |
|    ep_rew_mean      | -0.0457  |
|    exploration_rate | 0.2      |
| time/               |          |
|    episodes         | 132      |
|    fps              | 552      |
|    time_elapsed     | 1        |
|    total_timesteps  | 993      |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.54e-05 |
|    n_updates        | 223      |
----------------------------------
Eval num_timesteps=1000, episode_reward=-0.04 +/- 0.03
Episode length: 3.60 +/- 2.58
----------------------------------
| eval/               |          |
|    mean_ep_length   | 3.6      |
|    mean_reward      | -0.036   |
| rollout/            |          |
|    exploration_rate | 0.2      |
| time/               |          |
|    total_timesteps  | 1000     |
| train/              |          |
|    learning_rate    | 0.0001   |
|    loss             | 3.35e-05 |
|    n_updates        | 224      |
----------------------------------
New best mean reward!
 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1,000/1,000  [ 0:00:01 < 0:00:00 , 541 it/s ]
134
134
Wrapping array in numpy array...
Agent: [0 0]
Target: [9 9]
Action: 1
location: [0 0]
Completed in 0 steps with score of -0.01
(0, 0)
(9, 9)
['agent     ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ']
['          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', '          ', 'target    ']
Title: dqn path
Save path: ./graphs/64_64_64/dqnpath.pngdqn path
Execution time: 548.4176506996155 seconds
